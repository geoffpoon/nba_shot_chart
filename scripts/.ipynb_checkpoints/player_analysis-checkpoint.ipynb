{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large amount of data available related to the NBA seasons (prefessional basketball). After the introduction of SportVU cameras in every stadium, we now have the ability to know exactly where all five offensive players and all five defensive players are at every moment of the game.\n",
    "\n",
    "We also know where every shot is taken. I am interested in understanding where the top players are shooting from. More specifically, I am interested in the spatial distribution of shots taken by each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plot_court\n",
    "import sklearn.model_selection\n",
    "import pymc3 as pm\n",
    "import emcee\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the 2013-14 season that I downloaded from https://github.com/hwchase17/sportvu.\n",
    "\n",
    "I will also remove any unwanted columns and add a column (the shooter's team)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data and keep desired columns\n",
    "full_DatFrame = pd.read_csv('../dat/joined_shots_2013.csv')\n",
    "df = pd.DataFrame(full_DatFrame, \n",
    "                  columns = ['PLAYER_ID.1', 'PLAYER_NAME', \n",
    "                             'MATCHUP', 'LOCATION', 'TEAM_ID', \n",
    "                             'SHOT_DISTANCE', \n",
    "                             'PTS_TYPE', 'LOC_X', 'LOC_Y', \n",
    "                             'ACTION_TYPE', 'SHOT_TYPE',\n",
    "                             'SHOT_ATTEMPTED_FLAG', 'SHOT_MADE_FLAG'])\n",
    "\n",
    "# Add shooter's team column\n",
    "teamID_dict = plot_court.out_teamsDict()\n",
    "def out_teamAbbrev(teamID):\n",
    "    teamID_dict = plot_court.out_teamsDict()\n",
    "    return teamID_dict[teamID]['abbreviation']\n",
    "df['TEAM_ABBREV'] = pd.Series(map(out_teamAbbrev, df.TEAM_ID), index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list of the top 100 players in most shots taken during the 2013-14 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_players = 100\n",
    "top_players_shotNum = df.PLAYER_NAME.value_counts()[:num_players]\n",
    "top_players_nameList = top_players_shotNum.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = {}\n",
    "test_df = {}\n",
    "for i, player in enumerate(set(top_players_nameList)):  \n",
    "    temp = df[df.PLAYER_NAME == player]\n",
    "    train_df[player], test_df[player] = sklearn.model_selection.train_test_split(temp, test_size = 0.2)\n",
    "\n",
    "    \n",
    "player_shotHist_train = {}\n",
    "for i, player in enumerate(set(top_players_nameList)):  \n",
    "    temp = train_df[player]\n",
    "    hist2d, xedges, yedges, binnumber = scipy.stats.binned_statistic_2d(temp.LOC_X, temp.LOC_Y, \n",
    "                                                                        temp.SHOT_MADE_FLAG,\n",
    "                                                                        statistic='count',\n",
    "                                                                        bins=bins, \n",
    "                                                                        range=binRange)\n",
    "    player_shotHist_train[player] = hist2d.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I know which players we want to include in our analysis, I must decide how I want to describe each player's spatial distribution of shots.\n",
    "\n",
    "Instead of just analyzing the raw data, I wanted to use a model to estimate the underlying shot distribution that best describes the outcome. The raw data is sparse and there are a number of locations where a player did not take from. However, just because the player did not shoot from there over the course of the season does not mean that the probability of shooting from that location is zero. A model allows me to smoothen the shot distribution and have non-zero values for locations where no shots were taken (due to sparse sampling).\n",
    "\n",
    "It is reasonable to model the spatial location of each shot attempt using an inhomogeneous Poisson point process. The Poisson point process is a commonly used statistical model of randomly located points in space. This will help us estimate the average number of expected shots (not an integer) from each location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the problem, I will grid up the court into small boxes and estimate the number of shots in the region defined by the box.\n",
    "\n",
    "A finer grid is ideal. It will give me a better resolution of the shot distribution. However, a finer grid also requires more computation time to fit the model.\n",
    "\n",
    "I settled on 25 horizontal rows (along x-axis) and 18 vertical columns (along y-axis). This corresponds to bins that are 2x2 feet areas on the court."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of bins and range in each direction used to make the grid for analysis\n",
    "bins, binRange = ([25,18], [[-250,250], [-47.5,312.5]])\n",
    "\n",
    "hist2d, xedges, yedges, binnumber = scipy.stats.binned_statistic_2d(df.LOC_X, df.LOC_Y, \n",
    "                                                                    df.SHOT_MADE_FLAG,\n",
    "                                                                    statistic='count',\n",
    "                                                                    bins=bins, \n",
    "                                                                    range=binRange)\n",
    "# Creating the grid we will use for analysis\n",
    "XX, YY = np.meshgrid(xedges, yedges)\n",
    "binX_flat = XX.T[:-1,:-1].flatten()\n",
    "binY_flat = YY.T[:-1,:-1].flatten()\n",
    "binXY = np.column_stack((binX_flat.T, binY_flat.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_matrix = scipy.spatial.distance_matrix(binXY, binXY)\n",
    "\n",
    "def cov_func(dist_matrix, sigma2, phi2):\n",
    "    return sigma2 * np.exp( -(dist_matrix**2) / (2 * phi2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma2 = 60.\n",
    "phi2 = 25.**2\n",
    "\n",
    "cov_K = cov_func(dist_matrix, sigma2, phi2)\n",
    "det_cov_K = np.linalg.det(cov_K)\n",
    "inv_cov_K = np.linalg.inv(cov_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_prior(zn_v, det_cov_K, inv_cov_K):\n",
    "    part1 = -np.log(2 * np.pi * (det_cov_K**0.5))\n",
    "    part2 = -0.5 * np.dot(zn_v, np.dot(inv_cov_K, zn_v))\n",
    "    return part1 + part2\n",
    "\n",
    "def lambdaN_func(z0, zn_v):\n",
    "    return np.exp(z0 + zn_v)\n",
    "\n",
    "def ln_lambdaN_func(z0, zn_v):\n",
    "    return z0 + zn_v\n",
    "\n",
    "def ln_factorial(n):\n",
    "    # an improvement of the Sterling Approximation of log(n!)\n",
    "    # given by Srinivasa Ramanujan (Ramanujan 1988)\n",
    "    # scipy.misc.factorial stops worknig at large values of n\n",
    "    sterling = n * np.log(n) - n\n",
    "    correct = (1./6) * np.log(n * (1 + 4*n*(1 + 2*n))) + np.log(np.pi)/2\n",
    "    return sterling + correct\n",
    "\n",
    "def ln_likelihood(z0, zn_v, Xn_v):\n",
    "    part1 = -lambdaN_func(z0, zn_v)\n",
    "    part2 = Xn_v * ln_lambdaN_func(z0, zn_v)\n",
    "    part3 = np.nan_to_num(-ln_factorial(Xn_v))\n",
    "    #print(np.sum(part1), np.sum(part2), np.sum(part3))\n",
    "    #print(part3)\n",
    "    return np.sum(part1 + part2 + part3)\n",
    "\n",
    "def ln_postprob(z, Xn_v, det_cov_K, inv_cov_K):\n",
    "    z0 = z[0]\n",
    "    zn_v = z[1:]\n",
    "    return ln_prior(zn_v, det_cov_K, inv_cov_K) + ln_likelihood(z0, zn_v, Xn_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player = 'LeBron James'\n",
    "#################################################\n",
    "Xn_v = player_shotHist_train[player]\n",
    "z0_guess = np.log(np.mean(Xn_v))\n",
    "zn_v_guess = np.zeros(len(Xn_v))\n",
    "z_guess = np.append(z0_guess, zn_v_guess)\n",
    "\n",
    "neg_logLike = lambda *args: -ln_postprob(*args)\n",
    "result = scipy.optimize.minimize(neg_logLike, z_guess, \n",
    "                                 args=(Xn_v, det_cov_K, inv_cov_K))\n",
    "z_MaxLike = result[\"x\"]\n",
    "z0_MaxLike = z_MaxLike[0]\n",
    "zn_MaxLike = z_MaxLike[1:]\n",
    "lambdaN_v = np.exp(z0_MaxLike + zn_MaxLike)\n",
    "norm_lambdaN_v = lambdaN_v / np.sum(lambdaN_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_player_normLambda(player, norm_lambdaN_v):\n",
    "    LAMBDA_v = np.reshape(norm_lambdaN_v, bins)\n",
    "    ##########\n",
    "    extent = np.min(xedges), np.max(xedges), np.max(yedges), np.min(yedges)\n",
    "    \n",
    "    plt.imshow(LAMBDA_v.T, cmap=plt.cm.gist_heat_r, alpha=.9, vmax=0.1,\n",
    "               extent=extent)\n",
    "    plot_court.draw_court(outer_lines=True, lw=1.5)\n",
    "    \n",
    "    plt.xlim(-300,300)\n",
    "    plt.ylim(-100,500)\n",
    "    plt.title('%s: LGCP'%(player), fontsize=15)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_player_normLambda(player, norm_lambdaN_v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
